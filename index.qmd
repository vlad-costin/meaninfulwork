---
title: "Meaningful work measurement"
format: html
editor: visual
toc: true
toc-location: left
number-sections: true
---

## Loading package libraries and formatting data

```{r, include = F}
#|include: false
library(tidyverse)
library(lavaan)
library(semTools)
library(lavaan)
```

```{r, include = F}
data  <- here::here("data/efa_study.csv") %>% readr::read_csv() %>% 
  dplyr::select(-c(StartDate, EndDate, Status, Finished, RecordedDate, DistributionChannel, UserLanguage)) %>% 
  dplyr::rename_with(tolower)

names(data) <- gsub(' +', '_', names(data))    

# The item labelled "sex" is actually about gender

data <- data %>% 
   dplyr::mutate(
    sex = as_factor(sex), 
    ethnic = as_factor(ethnic), 
    relstat = as_factor(relstat), 
    child = as_factor(child), 
    educ = as_factor(educ), 
    jobcat = as_factor(jobcat), 
    emp = as_factor(emp), 
    yearsemp = as_factor(yearsemp), 
    yearsjob = as_factor(yearsjob), 
    worksit = as_factor(worksit), 
    level = as_factor(level)
  ) 

data <- data %>% 
  dplyr::mutate( 
    sex = forcats::fct_recode(data$sex, "woman" = "1", "man" = "2", "transgender woman" = "3", "transgender man" = "4", "genderqueer" = "5", "other" = "7"),
    ethnic = forcats::fct_recode(data$ethnic, "white" = "1", "black" = "2", "hispanic" = "3", "asian" = "4", "middle-eastern" = "5", "native american" = "6", "pacific islander" = "7", "other" = "8"), 
    relstat = forcats::fct_recode(data$relstat, "single" = "1", "married" = "2", "widowed" = "3", "separated" = "5", "divorced" = "6", "in a relationship" = "7"), 
    child = forcats::fct_recode(data$child, "no children" = "1", "1 child" = "2", "2 children" = "3", "3 children" = "4", "4 children" = "12", "5 or more children" = "13"), 
    educ = forcats::fct_recode(data$educ, "some high school" ="1", "high school" = "2", "some college" = "3", "bachelors degree" = "4", "masters degree" = "5", "doctorate" = "6"), 
    jobcat = forcats::fct_recode(data$jobcat, "arts, design, entertainment, media" = "1", "architecture and engineering" = "2", "building, grounds cleaning and maintenance" = "3", "business and financial" = "4", "community and social services" = "5", "computer and mathematical" = "6", "construction and extraction" = "7", "education, training and library" = "8", "farming, fishing and forestry" = "9", "food preparation and serving" = "10", "production" = "11", "office and administration support" = "12", "healthcarer practitioners and technical" = "13", "healthcare support" = "14", "installation, maintenance and repair" = "15", "legal" ="16", "life, physical and social science" = "17", "personal care and service" = "18", "protective service" = "19", "management" = "20", "transport and material moving" = "21", "sales" = "22"), 
    emp = forcats::fct_recode(data$emp, "full-time" = "1", "part-time" = "2", "student" = "3", "unemployed" = "5"),  
    yearsemp = forcats::fct_recode(data$yearsemp, "< 1 year" = "1", "1-5 years" = "2", "6-10 years" = "3", "11-20 years" = "4", "21-40 years" = "5", "40+ years" = "6"), 
    yearsjob = forcats::fct_recode(data$yearsjob,"< 1 year" = "1", "1-5 years" = "2", "6-10 years" = "3", "11-20 years" = "4", "21-40 years" = "5", "40+ years" = "6"), 
    worksit  = forcats::fct_recode(data$worksit, "work from home" = "1", "work away from home" = "2", "work from home and away from home" = "4", "other" = "5"),
    level = forcats::fct_recode(data$level, "top" = "1", "upper" = "2", "middle" = "3", "lower" = "4", "no mgmt" = "5", "self-employed" = "6")
    )

data %>% select(sex, ethnic,relstat, child, educ, jobcat, emp, yearsemp, yearsjob, worksit, level)%>% 
  summary()

summary(data)
N_total <-  nrow(data)
# N = 402


data_selection <- data %>% 
  dplyr::filter(attn1 == 2 & attn2 == 6) 
nrow(data_selection)
N_exclusions1 <-  nrow(data_selection)
# N = 390

key_var <- data_selection %>% 
  dplyr::select(gmw1:gmw8,coh1:coh6,coh7:coh16,purp1:purp9, purp10:purp16, sig1:sig17, socwor1:pg5)

data_selection <- data_selection %>% 
  filter(complete.cases(key_var))
N_exclusions2 <- nrow(data_selection)


```

Rules for data formatting:

-   All variable names are lower case (e.g., "Progress" would become "progress")

-   All spaces in variable names (if any) are turned into \_ (e.g., "duration in seconds" would become "duration\_ in_seconds"

Data exclusion rules:

-   The original dataset included *N* = `r N_total`

-   Participants after excluding those who failed any of the two attention checks (in other words, only retaining participants if attn1 == 2 & attn2 == 6): *N* = `r N_exclusions1`

-   Final participant numbers, after also excluding those who had any missing values on any of the key variables: *N* = `r N_exclusions2`

## Exploratory Factor Analysis: Analytic Approach

Initially, I aimed to use polychoric correlations as opposed to Pearson's r. Likert scale items are not ordinal but assume that the underlying variable is continuous, so Pearson's r (assumes continuous variables) may be unrealistic. There are many benefits to using polychoric correlations with ordinal data. For instance, when using parallel analysis (Horn, 1965) to determine number of factors from ordinal items, polychoric correlations are recommended as they tend to outperform Pearson's correlations when data is skewed (Garrido et al., 2013).

Polychoric correlations are more likely to elicit convergence issues (e.g., Timmerman & Lorenzo-Seva, 2011). Indeed, when I tried including all variables simultaneously in one EFA (coherence, purpose, significance, meaning, self-realization and personal growth), the parallel analysis and efa did not converge.

As an alternative, in talking to Sarah, we decided to focus on the proposed key dimensions of MIL: coherence, purpose, and significance/mattering. Then, as an additional step in trimming the items, I first inspected inter-item correlations using the following steps:

1.  Inter-item correlations across items suggested as part of the same factor

    For ease of interpretation, I first inspected inter-item correlations between items generated to capture each dimension of meaning separately (e.g., inter-item correlations for coherence). The aim was to remove items that had high inter-item correlations (to reduce redundancy) and to remove items that had very low correlations with other items--this would suggest that an item doesn't fit conceptually with the others. As such, the following rules were applied: (a) when two or more items were correlated at .90 or higher (suggesting that they have \>80% of variance in common), I retained only one item and the decision was often based on item wording (e.g., when one item was clearer than the other, more concise) or theoretical reasons (i.e., which item best captures the target theoretical construct); (b) when an item had correlations \<.30 with 2 or more items.

2.  Inter-item correlations across all items

    After the exclusions described at Step 1, I inspected inter-item correlations among all retained items. In order to reduce overlap between constructs, I removed items if they were correlated with items constructed to belong to a different construct at .80 or higher. The lower threshold for removal (from .90 to .80) is because, here, the aim wasn't to remove similar items, it was to clarify the factor structure; to that end, a correlation of .80-.90 may still be problematic.

##### Exploratory factor analysis (EFA)

After obtaining the final item selection, I then ran an exploratory factor analysis using the remaining items.

-   I used the "wls" estimation method as this seemed to work nicely with polychoric data and seems to match the "dwls" (the robust equivalent of "wls") which is available in lavaan and recommended for use with polychoric data in CFA.

-   I used an oblique rotation across all models

-   **Factor loadings.** Items were considered for removal if they had a primary factor loading lower than .30. In order to ensure distinct factors, items were removed if (a) they had a secondary factor loading \>.30 (no removals) or (b) if the difference between primary and the next highest secondary loading exceeded .30

##### Measurement model (or confirmatory factor analysis, CFA)

I also ran a CFA with the final items suggested after the EFA step. This is not a substitute for confirming the obtained factor structure with a new sample (we'll still need to do that!). However, this allowed me to model correlations between the newly obtained latent variables. It also allowed me to test whether a more parsimonious factor structure would be just as good; I did this by creating models sequentially collapsing factors in all possible combinations and comparing them to the original factor structure. Finally, the CFA also allows me to obtained more detailed global fit indices.

## Step 0: Preliminary analyses

### Coherence

::: panel-tabset
#### Summary

```{r, echo = F}

data_selection %>% 
  dplyr::select(coh1:coh6, coh7:coh16) %>% summary()


```

#### Histograms

```{r, echo = F}

coh_tidy <- data_selection %>% 
  select(coh1:coh6, coh7:coh16) %>% 
  tidyr::pivot_longer(
    cols = coh1:coh16, 
    names_to = "Item",
    values_to = "Response"
  ) 
ggplot2::ggplot(coh_tidy, aes(Response)) +
  geom_histogram(binwidth = 1, alpha = 0.5) +
  labs(y = "Frequency") +
  facet_wrap (~Item, ncol = 4) +
  theme_minimal()
```
:::

### Purpose

::: panel-tabset
#### Summary

```{r, echo = F}
data_selection %>% 
  dplyr::select(purp1:purp9, purp10:purp16) %>% summary()

```

#### Histograms

```{r, echo = F}
purp_tidy <- data_selection %>% 
  select(c(purp1:purp9), c(purp10:purp16)) %>% 
  tidyr::pivot_longer(
    cols = purp1:purp16, 
    names_to = "Item",
    values_to = "Response"
  ) 
ggplot2::ggplot(purp_tidy, aes(Response)) +
  geom_histogram(binwidth = 1, alpha = 0.5) +
  labs(y = "Frequency") +
  facet_wrap (~Item, ncol = 4) +
  theme_minimal()
```
:::

### Significance

::: panel-tabset
#### Summary

One of the items (sig5 My work really makes no difference to the world) was reverse-phrased and this is reflected in the distribution of scores for sig5

```{r, echo = F}
data_selection %>% 
  dplyr::select(sig1:sig17, socwor1:socwor6) %>% summary()
```

#### Histograms

```{r, echo = F}
sig_tidy <- data_selection %>% 
  select(sig1:sig17, socwor1:socwor6) %>% 
  tidyr::pivot_longer(
    cols = sig1:socwor6, 
    names_to = "Item",
    values_to = "Response"
  ) 
ggplot2::ggplot(sig_tidy, aes(Response)) +
  geom_histogram(binwidth = 1, alpha = 0.5) +
  labs(y = "Frequency") +
  facet_wrap (~Item, ncol = 4) +
  theme_minimal()
```
:::

### Global meaning in life

::: panel-tabset
#### Summary

```{r, echo = F}
data_selection %>% 
  dplyr::select(gmw1:gmw8) %>% summary()
```

#### Histogram

```{r, echo = F}
gmw_tidy <- data_selection %>% 
  select(gmw1:gmw8) %>% 
  tidyr::pivot_longer(
    cols = gmw1:gmw8, 
    names_to = "Item",
    values_to = "Response"
  ) 
ggplot2::ggplot(gmw_tidy, aes(Response)) +
  geom_histogram(binwidth = 1, alpha = 0.5) +
  labs(y = "Frequency") +
  facet_wrap (~Item, ncol = 4) +
  theme_minimal()
```
:::

### Self-realization and personal growth

::: panel-tabset
#### Summary

```{r, echo = F}
data_selection %>% 
  dplyr::select(sr1:sr8, pg1:pg5) %>% summary()
```

#### Histograms

```{r, echo = F}
srpg_tidy <- data_selection %>% 
  select(sr1:sr8, pg1:pg5) %>% 
  tidyr::pivot_longer(
    cols = sr1:pg5, 
    names_to = "Item",
    values_to = "Response"
  ) 
ggplot2::ggplot(srpg_tidy, aes(Response)) +
  geom_histogram(binwidth = 1, alpha = 0.5) +
  labs(y = "Frequency") +
  facet_wrap (~Item, ncol = 4) +
  theme_minimal()
```
:::

## Step 1: Correlations

### Coherence

::: panel-tabset
##### Correlations with all items

**Low correlations (r\<.30)**

-   coh9 with 3 other items coh7 and coh10, coh12 with 2 other items

```{r, echo = F}
coh_poly <- data_selection %>% select(coh1:coh6, coh7:coh16) %>% psych::polychoric()
coh_rho <- coh_poly$rho
psych::cor.plot(coh_rho, upper = FALSE, cex = .80)
```

##### Correlations after removals

```{r, echo = F}
coh_poly1 <- data_selection %>% select(coh1:coh6, coh8, coh11, coh13:coh16) %>% psych::polychoric()
coh_rho1 <- coh_poly1$rho
psych::cor.plot(coh_rho1, upper = FALSE, cex = .80)
```
:::

### Purpose

::: panel-tabset
##### Correlations with all items

**High correlations (\>.90)**

-   purp1 highly correlated with 3 items; removed purp1 I have discovered work that has a satisfying purpose.

-   purp10 and purp11 were correlated at .91; removed purp10 My work tasks feel purposeful.

```{r, echo = F}
pur_poly <- data_selection %>% select(purp1:purp9, purp10:purp16) %>% psych::polychoric()
pur_rho <- pur_poly$rho
psych::cor.plot(pur_rho, upper = FALSE, cex = .80)
```

##### Correlations after removals

```{r, echo = F}
pur_poly1 <- data_selection %>% select(purp2:purp9, purp11:purp16) %>% psych::polychoric()
pur_rho1 <- pur_poly1$rho
psych::cor.plot(pur_rho1, upper = FALSE, cex = .80)
```
:::

### Significance

::: panel-tabset
##### Correlations with all items

**High correlations (\>.90)**

-   sig11, sig12, sig13 and sig16 are highly correlated with one another and some of the other items; I chose only one of these to retain; we removed sig12, sig13, and sig16. Kept sig11 The work I do is very important to me.

-   sig14 and sig2 were highly correlated so I removed sig2 as this seemed a bit wordy (My job is very significant and important in the broader scheme of things)

-   sig4 and sig3 were highly correlated so I removed sig4 (The work performed on my job has a significant impact on people outside the organization) as it just seemed like a wordier version of sig3

-   socwor1, socwor2, socwor4 and socwor5 are highly correlated with one another. socwor1 was also highly correlated with socwor6. Removed: socwor1, socwor2 and socwor5 (kept socwor4 I feel important to my organization)

```{r, echo = F}
sig_poly <- data_selection %>% select(sig1:sig17, socwor1:socwor6) %>% psych::polychoric()
sig_rho <- sig_poly$rho
psych::cor.plot(sig_rho, upper = FALSE, cex = .80)
```

##### Correlations after removals

```{r, echo = F}
sig_poly1 <- data_selection %>% select(sig1, sig3, sig5:sig11, sig14, sig15, socwor3, socwor4, socwor6) %>% psych::polychoric()
sig_rho1 <- sig_poly1$rho
psych::cor.plot(sig_rho1, upper = FALSE, cex = .80)
```
:::

### Global MIL

::: panel-tabset
##### Correlations with all items

**High correlations (\>.90)**

-   Removed gmw3, gmw4, gmw5, gmw8 for being highly correlated with 5 items gmw2 anf gmw6 were highly correlated at .96; removed gmw2

```{r, echo = F}
gmw_poly <- data_selection %>% select(gmw1:gmw8) %>% psych::polychoric()
gmw_rho <- gmw_poly$rho
psych::cor.plot(gmw_rho, upper = FALSE, cex = .80)
```

##### Correlations after removals

```{r, echo = F}
gmw_poly1 <- data_selection %>% select(gmw1, gmw6, gmw7) %>% psych::polychoric()
gmw_rho1 <- gmw_poly1$rho
round(gmw_rho1, 2)
psych::cor.plot(gmw_rho1, upper = FALSE, cex = .80)
```
:::

### All meaning variables together (after earlier removals)

::: panel-tabset
##### Correlations with all items

Sadly, there are so many items, that these don't display clearly, but you can run the code and pop out the output window and enlarge it to inspect more closely.

**High correlations (\>.90)**

-   purp9 and gmw7 were highly correlated .90 so we removed purp9

-   purp11, sig11 and sig15 were correlated at .80 or higher with all gmw items so were removed

-   purp2 was correlated with most sig items at \>.80; removed purp2

-   sig10 and sig14 was correlated at \>.80 with 2 of the 3 gmw items and were removed

-   purp5 correlated with gmw1 \>.80; removed purp5

-   purp16 correlated with gmw7 and sig8 at \>.80; removed purp16

-   sig6 and sig8 correlated with gmw7 at \>.80; removed sig6 and sig8

```{r, echo = F}
everything_poly <- data_selection %>% select(gmw1, gmw6, gmw7,coh1:coh6, coh8, coh11, coh13:coh16, purp2:purp9, purp11:purp16, sig1, sig3, sig5:sig11, sig14, sig15, socwor3, socwor4, socwor6) %>% psych::polychoric()
everything_rho <- everything_poly$rho
psych::cor.plot(everything_rho, upper = FALSE, cex = .80)
```

##### Correlations after removals

```{r, echo = F}
everything_poly1 <- data_selection %>% select(gmw1, gmw6, gmw7,coh1:coh6, coh8, coh11, coh13:coh16, purp3, purp4, purp6:purp8, purp12:purp15, sig1, sig3, sig5, sig7, sig9, socwor3, socwor4, socwor6) %>% psych::polychoric()
everything_rho1 <- everything_poly1$rho
psych::cor.plot(everything_rho1, upper = FALSE, cex = .80)
```
:::

## Step 2: Exploratory factor analysis

::: panel-tabset
### Bartlett's chi-square test and KMO

```{r, echo = F}
everything_nogmw <- data_selection %>% 
  dplyr::select(coh1:coh6, coh8, coh11, coh13:coh16, purp3, purp4, purp6:purp8, purp12:purp15, sig1, sig3, sig5, sig7, sig9, socwor3, socwor4, socwor6) 

ev_nogmw_poly <- data_selection %>% select(coh1:coh6, coh8, coh11, coh13:coh16, purp3, purp4, purp6:purp8, purp12:purp15, sig1, sig3, sig5, sig7, sig9, socwor3, socwor4, socwor6) %>% psych::polychoric()
ev_nogmw_rho <- ev_nogmw_poly$rho

psych::cortest.bartlett(ev_nogmw_rho, n = nrow(everything_nogmw))
psych::KMO(ev_nogmw_rho)
```

### Factor extraction (parallel analysis)

```{r, echo = F}
psych::fa.parallel(everything_nogmw, fa="fa", fm = "wls", quant = .95)
```

### 3-factor model

Items were considered for removal if they had a primary factor loading lower than .30. In order to ensure distinct factors, items were removed if (a) they had a secondary factor loading \>.30 (no removals) or (b) if the difference between primary and the next highest secondary loading exceeded .30 Removed: purp6, purp8, purp12, sig7, coh2, coh5, socwor6, sig9 Removed coh1 for conceptual reasons (not fitting with the purpose factor) Removed socwor4 for conceptual reasons (not fitting with the purpose factor) The gmw items were removed because they didn't fit into their factors and two of the items had unacceptable cross-loadings according to the rules displayed above

```{r, echo =F}
everything_fa <- psych::fa(everything_nogmw,
                    nfactors = 3,
                    scores = "tenBerge", 
                    cor = "poly", 
                    fm = "wls"
                    )
everything_fa
parameters::model_parameters(everything_fa, sort = TRUE, threshold = 0.2)
```

### 3-factor model FINAL

```{r, echo = F}
ev_nogmw_poly1 <- data_selection %>% select(coh3, coh4, coh6, coh8, coh11, coh13:coh16, purp3, purp4, purp7, purp13:purp15, sig1, sig3, sig5, socwor3) %>% psych::polychoric()
ev_nogmw_rho1 <- ev_nogmw_poly1$rho

everything_nogmw1 <- data_selection %>% 
  dplyr::select(coh3, coh4, coh6, coh8, coh11, coh13:coh16, purp3, purp4, purp7, purp13:purp15, sig1, sig3, sig5, socwor3) 

everything_fa1 <- psych::fa(everything_nogmw1,
                    nfactors = 3,
                    scores = "tenBerge", 
                    cor = "poly", 
                    fm = "wls"
                    )
everything_fa1
parameters::model_parameters(everything_fa1, sort = TRUE, threshold = 0.2)
```
:::

## Step 3: Measurement model (confirmatory factor analysis)

### CFA model

Diagonal-weighed least-squares estimation with robust standard errors

Fit was great. CFI = .996, RMSEA = .73, SRMR = .053 Correlations between factors were high: coh \~ purp at .612, coh \~ sig at .506, purp \~ sig at .772

```{r, echo = F}
all_mod <- '
coh =~ coh13 + coh14 + coh16 + coh6 + coh8 + coh3 + coh4 + coh15 + coh11
purp =~ purp7 + purp3 + purp13 + purp4 + purp15 + purp14
sig  =~ sig3 + sig1 +sig5 + socwor3
'

all_out <- cfa(all_mod, data=data_selection, ordered = T, estimator = "dwls")
summary (all_out, standardized = TRUE, fit.measures = TRUE)
```

### Alternative models

::: panel-tabset
#### Coh and purp items collapsed onto one factor (2-factor model)

```{r, echo = F}
cohpurp_mod <- '
cohpurp =~ coh13 + coh14 + coh16 + coh6 + coh8 + coh3 + coh4 + coh15 + coh11 + purp7 + purp3 + purp13 + purp4 + purp15 + purp14
sig  =~ sig3 + sig1 +sig5 + socwor3
'
cohpurp_out <- cfa(cohpurp_mod, data=data_selection, ordered = T, estimator = "dwls")
summary (cohpurp_out, standardized = TRUE, fit.measures = TRUE)
```

#### Coh and sig items collapsed onto one factor (2-factor model)

```{r, echo = F}
cohsig_mod <- '
cohsig =~ coh13 + coh14 + coh16 + coh6 + coh8 + coh3 + coh4 + coh15 + coh11 + sig3 + sig1 +sig5 + socwor3
purp =~ purp7 + purp3 + purp13 + purp4 + purp15 + purp14
'
cohsig_out <- cfa(cohsig_mod, data=data_selection, ordered = T, estimator = "dwls")
summary (cohsig_out, standardized = TRUE, fit.measures = TRUE)
```

#### Purp and sig items collapsed onto one factor (2-factor model)

```{r, echo = F}
purpsig_mod <- '
coh =~ coh13 + coh14 + coh16 + coh6 + coh8 + coh3 + coh4 + coh15 + coh11
purpsig =~ purp7 + purp3 + purp13 + purp4 + purp15 + purp14 + sig3 + sig1 +sig5 + socwor3
'
purpsig_out <- cfa(purpsig_mod, data=data_selection, ordered = T, estimator = "dwls")
summary (purpsig_out, standardized = TRUE, fit.measures = TRUE)
```

#### Coh, purpose and sig items collapsed onto one factor (1-factor model)

```{r, echo = F}
cohpurpsig_mod <- '
cohpurpsig =~ coh13 + coh14 + coh16 + coh6 + coh8 + coh3 + coh4 + coh15 + coh11 + purp7 + purp3 + purp13 + purp4 + purp15 + purp14 + sig3 + sig1 +sig5 + socwor3
'
cohpurpsig_out <- cfa(cohpurpsig_mod, data=data_selection, ordered = T, estimator = "dwls")
summary (cohpurpsig_out, standardized = TRUE, fit.measures = TRUE)
```

#### Nested model-comparisons (1-factor model)

All alternative models were a significantly worse fit to the data compared to our 3-factor model. This suggests that, despite the high correlations between factors, a three-factor solution is most appropriate.

```{r, echo = F}
anova(all_out, cohpurp_out)
anova(all_out, cohsig_out)
anova(all_out, purpsig_out)
anova(all_out, cohpurpsig_out)
```
:::
